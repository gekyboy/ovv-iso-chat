# ============================================================================
# OVV ISO Chat v3.9.2 - Docker Compose
# ============================================================================
# Avvia i servizi necessari con: docker-compose up -d
# ============================================================================

version: '3.8'

services:
  # ==========================================================================
  # QDRANT - Vector Database
  # ==========================================================================
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant-ovv
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

# ==========================================================================
# NOTE:
# ==========================================================================
# Ollama NON è incluso in docker-compose perché:
# 1. Richiede accesso diretto alla GPU NVIDIA
# 2. È più efficiente installarlo nativamente su Windows
#
# Per installare Ollama:
#   1. Scarica da https://ollama.ai
#   2. Installa e avvia: ollama serve
#   3. Pull modello: ollama pull llama3.1:8b-instruct-q4_K_M
# ==========================================================================

volumes:
  qdrant_data:


