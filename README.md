# ğŸ­ OVV ISO Chat v3.9.1

> Il tuo assistente **discorsivo e proattivo** per i documenti ISO aziendali. Chiedi quello che ti serve, lui trova la risposta nei documenti, te la spiega in dettaglio e ti suggerisce **moduli e strumenti correlati**.

> ğŸ†• **v3.9.1**: **PDF Consultabili & Citazioni Leggibili** - I PDF si aprono in sidebar, le citazioni mostrano titoli italiani tra virgolette, fonti separate da glossario!

> ğŸ“‚ **Nuovo in v3.9.1**: Comando `/documenti` per gestire la cartella documenti direttamente dalla chat (F10)!

## Indice

- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“– Guida Utente](#-guida-utente)
- [ğŸ”¬ Deep Dive Tecnico](#-deep-dive-tecnico)
- [ğŸ“œ Appendici](#-appendici)

---

# ğŸš€ Quick Start

**Prerequisiti**: Windows 10+, GPU NVIDIA con 6GB+ VRAM, Docker Desktop attivo.

## 1ï¸âƒ£ Avvia

> ğŸ“ **Doppio click su:** `avvia_chat.bat`

## 2ï¸âƒ£ Apri il browser

Vai su: **http://localhost:7866**

## 3ï¸âƒ£ Login

| Chi sei | Username | Password |
|---------|----------|----------|
| ğŸ”´ **Admin** | `admin` | `admin123` |
| ğŸŸ¡ **Ingegnere** | `engineer` | `eng123` |
| ğŸŸ¢ **Utente** | `user` | `user123` |

## 4ï¸âƒ£ Prova subito questi comandi

```
Come gestisco i rifiuti pericolosi?     â†’ Domanda normale
/teach MR-10_01                          â†’ Spiega come compilare un modulo
/status                                  â†’ Stato del sistema
```

---

# ğŸ“– Guida Utente

## â“ Cos'Ã¨ OVV ISO Chat?

Immagina di avere centinaia di documenti aziendali: procedure, istruzioni, moduli. Cercare un'informazione significa sfogliare PDF, perdere tempo, rischiare di non trovare nulla.

**OVV ISO Chat risolve questo problema.**

Ãˆ come avere un collega esperto che ha letto TUTTI i documenti e puÃ² risponderti in linguaggio naturale. Gli chiedi *"Come gestire i rifiuti?"* e lui ti risponde citando esattamente le procedure giuste.

### ğŸ¯ A cosa serve?

- **Trovare informazioni velocemente** nei documenti ISO
- **Capire le procedure** senza leggere manuali interi
- **Avere risposte con fonti** sempre citate
- **Ricordare le tue preferenze** per risposte personalizzate

### ğŸ¢ Per chi Ã¨ pensato?

- Quality Manager, HSE Manager
- Responsabili di produzione
- Auditor interni
- Operatori che consultano procedure

---

## ğŸ‘¤ Cosa Puoi Fare in Base al Tuo Ruolo

### ğŸŸ¢ Utente (`user`)
*L'utente base puÃ² usare la chat e salvare le proprie preferenze.*

| Cosa puoi fare | Come si fa |
|----------------|------------|
| ğŸ’¬ **Fare domande** | Scrivi la domanda e premi Invio |
| ğŸ“– **Capire un documento** | `/teach MR-10_01` |
| ğŸ’¾ **Salvare una preferenza** | `/memoria preference Preferisco risposte brevi` |
| ğŸ’¡ **Salvare un fatto** | `/memoria fact Il Quick Kaizen dura max 5 giorni` |
| ğŸ“š **Cercare nel glossario** | `/glossario WCM` |
| ğŸ“¤ **Proporre per tutti** | `/propose fact CDL significa Centro Di Lavoro` |
| ğŸ“Š **Vedere lo stato** | `/status` |
| ğŸ“‚ **Vedere cartella documenti** | `/documenti` |
| ğŸ‘ğŸ‘ **Dare feedback** | Clicca i pulsanti dopo ogni risposta |

### ğŸŸ¡ Ingegnere (`engineer`)
*L'ingegnere puÃ² fare tutto quello che fa l'utente, piÃ¹:*

| Cosa puoi fare in piÃ¹ | Come si fa |
|-----------------------|------------|
| ğŸ‘ï¸ **Vedere proposte in attesa** | `/pending` |
| âŒ **Rifiutare una proposta** | `/reject abc123 Motivo del rifiuto` |
| ğŸ‘¥ **Vedere memorie altri utenti** | `/memorie mario` |
| ğŸ“‚ **Cambiare cartella documenti** | `/documenti D:\MieiPDF` |
| ğŸ“‚ **Path recenti** | `/documenti recenti` |

### ğŸ”´ Amministratore (`admin`)
*L'admin puÃ² fare tutto, incluso approvare e gestire utenti.*

| Cosa puoi fare in piÃ¹ | Come si fa |
|-----------------------|------------|
| âœ… **Approvare una proposta** | `/approve abc123` |
| ğŸŒ **Aggiungere memoria globale** | `/global add fact Gli audit sono mensili` |
| ğŸ“š **Aggiungere al glossario** | `/glossario add QK = Quick Kaizen` |
| ğŸ›ï¸ **Pannello Admin visuale** | Vai su **http://localhost:8501** |

---

## ğŸ’¬ Tutti i Comandi

### Domande Normali
```
Come gestisco i rifiuti pericolosi?
Cosa dice la procedura PS-06_01?
Qual Ã¨ la differenza tra NC e AC?
```

### Comandi Speciali (Tutti gli utenti)
```
/teach MR-10_01                              â†’ Spiega come compilare il modulo
/memoria fact WCM significa World Class      â†’ Salva un fatto
/memoria preference Risposte dettagliate     â†’ Salva una preferenza
/glossario NC                                â†’ Cerca significato acronimo
/glossario add QK = Quick Kaizen             â†’ Aggiunge termine (se admin)
/status                                      â†’ Stato del sistema
/propose fact CDL = Centro Di Lavoro         â†’ Proponi per approvazione Admin
/history                                     â†’ Cronologia tue conversazioni (R28)
/history 20                                  â†’ Ultime 20 sessioni
/history today                               â†’ Solo sessioni di oggi
/documenti                                   â†’ Mostra cartella documenti attuale
```

### Comandi Admin/Engineer
```
/documenti D:\MieiPDF                        â†’ Cambia cartella documenti (F10)
/documenti recenti                           â†’ Mostra path usati di recente
/documenti reset                             â†’ Torna alla cartella di default
```

```
/pending                                     â†’ Lista proposte in attesa
/reject abc123 Non corretto                  â†’ Rifiuta proposta
/approve abc123                              â†’ Approva proposta (solo Admin)
/global add fact Gli audit sono mensili      â†’ Memoria globale (solo Admin)
/memorie mario                               â†’ Vedi memorie di un utente
/gaps                                        â†’ Lacune segnalate dagli utenti (R19)
/acronyms                                    â†’ Acronimi estratti automaticamente (R05)
/acronyms approve WCM                        â†’ Approva acronimo â†’ glossario
/acronyms reject XYZ motivo                  â†’ Rifiuta acronimo estratto
/teach_stats                                 â†’ Statistiche assistenza compilazione (R16)
/history all                                 â†’ Cronologia tutti gli utenti (R28)
```

---

## ğŸ“ Esempi d'Uso

### Esempio 1: Domanda Semplice

**Tu scrivi:**
```
Come gestire i rifiuti pericolosi?
```

**Il sistema risponde:**
```
La gestione dei rifiuti pericolosi Ã¨ regolamentata dalla procedura PS-06_01 
e dalle istruzioni operative IL-06_02.

**Punti chiave:**

1. **Identificazione**: I rifiuti pericolosi devono essere identificati 
   secondo il codice CER e classificati per tipologia.

2. **Stoccaggio**: Utilizzare contenitori omologati con etichettatura 
   conforme. Lo stoccaggio temporaneo non deve superare i 12 mesi.

3. **Registrazione**: Compilare il registro di carico/scarico (MR-06_01) 
   entro 10 giorni dall'operazione.

4. **Trasporto**: Solo trasportatori autorizzati con formulario FIR.

ğŸ“š **Fonti:** PS-06_01, IL-06_02, MR-06_01
â±ï¸ *2847ms*
```

### Esempio 2: Usare Acronimi

**Tu scrivi:**
```
Cosa dice il SGI sulla gestione delle NC?
```

**Il sistema capisce** che SGI = Sistema di Gestione Integrato e NC = Non ConformitÃ , e ti risponde in modo appropriato citando le procedure corrette.

### Esempio 2.5: Disambiguazione Intelligente (R06)

**Tu scrivi:**
```
Mostrami le NC
```

**Il sistema riconosce** che NC Ã¨ ambiguo (puÃ² essere "Non ConformitÃ " o "Nota di Credito") e non c'Ã¨ abbastanza contesto. Ti chiede:

```
â“ **NC** puÃ² significare:

**1. Non ConformitÃ ** â­ _tua preferenza abituale_
**2. Nota di Credito**

Quale intendi in questo caso?
```

**Tu clicchi** su "Non ConformitÃ " e il sistema:
1. Risponde alla tua domanda
2. **Ricorda** la tua preferenza per la prossima volta (ma senza forzarla!)

**Nota**: Se avessi scritto "Mostrami le NC dell'audit", il sistema avrebbe capito automaticamente che intendevi "Non ConformitÃ " dal contesto "audit".

### Esempio 3: Imparare a Compilare un Modulo

**Tu scrivi:**
```
/teach MR-10_01
```

**Il sistema risponde:**
```
ğŸ“– **Come compilare MR-10_01:**

Il modulo MR-10_01 Ã¨ il **Modulo di Segnalazione Miglioramento** utilizzato 
per proporre Quick Kaizen e iniziative di miglioramento continuo.

| Campo | Descrizione | Esempio |
|-------|-------------|---------|
| Data | Data della segnalazione | 06/12/2025 |
| Proponente | Nome e reparto | Mario Rossi - Produzione |
| Area | Area di intervento | Linea 3 - Assemblaggio |
| Proposta | Soluzione proposta | Riorganizzare layout |
| Benefici | Risultati previsti | -15% tempo ciclo |

**Note importanti:**
- Per Quick Kaizen, l'implementazione deve avvenire entro 5 giorni
- Dopo implementazione, compilare la sezione "Risultati ottenuti"

ğŸ“š **Riferimento:** PS-10_01 - Gestione Miglioramento Continuo
```

### Esempio 4: Correlazioni Automatiche (v3.9)

**Tu scrivi:**
```
Ho avuto un infortunio sul lavoro, cosa devo fare?
```

**Il sistema risponde:**
```
Per gestire un infortunio sul lavoro devi seguire la procedura PS-06_01 
e utilizzare il modulo Safety EWO (MR-06_01).

**Passi principali:**
1. Segnala immediatamente l'infortunio al responsabile
2. Compila il modulo MR-06_01 - Safety EWO entro 24 ore
3. Avvia l'analisi causa radice con i 5 PerchÃ©

ğŸ“Œ **Strumenti da utilizzare insieme:**
- 5 PerchÃ© â†’ analisi causa radice
- 5W1H â†’ raccolta dati iniziali
- 4M Ishikawa â†’ diagramma causa-effetto

âš ï¸ **IMPORTANTE**: NON usare MR-06_02 (Near Miss) - quello Ã¨ per 
quasi-incidenti SENZA lesioni!

ğŸ“š **Fonti:** PS-06_01, MR-06_01_Safety EWO, IL-06_03
â±ï¸ *3847ms*
```

**Nota:** Il sistema ha capito che si tratta di un infortunio REALE (non un near miss) e ha suggerito il modulo corretto con gli strumenti correlati.

### Esempio 5: Salvare una Preferenza

**Tu scrivi:**
```
/memoria preference Preferisco risposte brevi e con elenchi puntati
```

**Il sistema risponde:**
```
âœ… Preferenza salvata! Le prossime risposte saranno piÃ¹ brevi e strutturate.
```

---

## ğŸ›ï¸ Pannello Admin (Solo Amministratori)

Se sei **admin**, hai accesso anche al pannello visuale:

**URL:** http://localhost:8501

| Sezione | Cosa puoi fare |
|---------|----------------|
| ğŸ“Š **Dashboard** | Vedere statistiche e KPI del sistema |
| ğŸ“‹ **Proposte** | Approvare/rifiutare proposte degli utenti |
| ğŸ“š **Glossario** | Aggiungere, modificare, eliminare acronimi |
| ğŸ§  **Memorie** | Vedere e gestire le memorie di tutti |
| ğŸ‘¥ **Utenti** | Creare, modificare, eliminare utenti |

---

## ğŸ‘ğŸ‘ Sistema Feedback

Dopo ogni risposta, puoi valutarla con i pulsanti **Utile** o **Non utile**.

Il sistema **impara** dai tuoi feedback:
- Le risposte che ti piacciono diventano piÃ¹ probabili
- Le risposte che non ti piacciono vengono penalizzate

Questo rende il sistema sempre piÃ¹ personalizzato per te!

---

## ğŸ§  Apprendimento Automatico (v3.5)

Il sistema impara **automaticamente** dalle tue azioni, senza che tu debba fare nulla:

| Cosa fai | Cosa impara il sistema |
|----------|------------------------|
| ğŸ“‹ **Clicchi** su una fonte citata | "Questo documento Ã¨ utile" |
| ğŸ“ **Copi** parte della risposta | "Questa informazione Ã¨ rilevante" |
| â±ï¸ **Leggi** a lungo una risposta | "Contenuto interessante" |
| ğŸ”„ **Riformuli** la domanda | "La risposta non era soddisfacente" |
| âœ… **Completi** un /teach | "Questa spiegazione funziona" |

**Consenso Multi-Utente:** Quando piÃ¹ utenti confermano la stessa cosa (es. cliccano la stessa fonte, copiano la stessa definizione), il sistema puÃ² promuovere automaticamente quella conoscenza a **globale** per tutti gli utenti.

> ğŸ’¡ **Esempio**: Se 3 utenti diversi cliccano sulla fonte PS-06_01 quando chiedono "gestione rifiuti", il sistema capisce che quel documento Ã¨ rilevante per quel tema.

---

## ğŸ“„ Fonti nelle Risposte

Ogni risposta mostra le **fonti consultate** in modo chiaro e organizzato (v3.9.1):

```
---
ğŸ“š **Fonti consultate:**
- ğŸ“„ PS-06_01_Rev.04_Gestione della sicurezza negli ambienti di lavoro
- ğŸ“„ IL-06_02_Rev.02_Rifiuti pericolosi

ğŸ“– **Termini glossario:**
- ğŸ“ Emergency Work Order
```

**NovitÃ  v3.9.1:**
- **Titoli leggibili nel testo**: Le citazioni nel testo mostrano il titolo italiano tra virgolette (es. `"Gestione della sicurezza"`) invece del codice tecnico (es. `PS-06_01`)
- **Nome completo nel footer**: Include `doc_id_Rev.XX_Titolo italiano`
- **Separazione PDF/Glossario**: I documenti PDF sono separati dai termini del glossario
- **PDF consultabili**: Clicca sul nome per aprire il PDF nella sidebar (non download)
- **Apertura alla pagina giusta**: Il PDF si apre alla pagina corretta

---

# ğŸ”¬ Deep Dive Tecnico

> âš ï¸ **Questa sezione Ã¨ per chi vuole capire come funziona il sistema internamente.**
> Se vuoi solo usarlo, la Guida Utente Ã¨ sufficiente.

---

## ğŸ”® Come Funziona? (Spiegato Semplice)

Il sistema funziona in due fasi: prima **impara** dai documenti, poi **risponde** alle domande.

### Fase 1: Imparare dai Documenti ğŸ“šâ¡ï¸ğŸ§ 

```
I tuoi PDF â”€â”€â–º Lettura â”€â”€â–º Comprensione â”€â”€â–º Memoria Digitale
```

1. **Leggiamo i PDF** - Il sistema apre ogni documento e estrae il testo
2. **Dividiamo in pezzi** - Ogni documento viene spezzato in parti piÃ¹ piccole (chunk) per essere piÃ¹ facile da cercare
3. **Creiamo "impronte digitali"** - Ogni pezzo viene trasformato in numeri (embedding) che ne catturano il significato
4. **Salviamo in memoria** - Questi numeri finiscono in un database speciale che sa cercare per significato

Pensa ai chunk come post-it: invece di cercare in un libro intero, cerchi tra tanti post-it organizzati per argomento.

### Fase 2: Rispondere alle Domande ğŸ—£ï¸â¡ï¸ğŸ’¡

```
La tua domanda â”€â”€â–º Ricerca â”€â”€â–º Selezione â”€â”€â–º Risposta intelligente
```

1. **Capiamo la domanda** - Espandiamo acronimi (SGI â†’ Sistema di Gestione Integrato) e arricchiamo il contesto
2. **Cerchiamo i pezzi giusti** - Troviamo i chunk piÃ¹ simili alla tua domanda (come un motore di ricerca super intelligente)
3. **Filtriamo il meglio** - Usiamo due "giudici" AI per tenere solo i documenti veramente rilevanti
4. **Generiamo la risposta** - Un modello di linguaggio legge i documenti selezionati e scrive una risposta chiara

### Come si Incontrano? ğŸ¤

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  La tua domanda â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Comprensione  â”‚  "Cosa sta chiedendo?"
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Memoria delle  â”‚     â”‚     â”‚   I documenti   â”‚
     â”‚  tue preferenze â”‚     â”‚     â”‚   trasformati   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚              â”‚              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Il cervello AI â”‚  "Risposta basata su tutto"
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    RISPOSTA     â”‚
                    â”‚  + Fonti citate â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Ãˆ come un incrocio dove:
- **Da sinistra** arrivano i documenti preparati
- **Da destra** arrivano le tue preferenze e la storia
- **Al centro** l'AI mette tutto insieme

---

## ğŸ› ï¸ Tecnologie Utilizzate

### I "Cervelli" dell'AI

| Componente | Modello | Cosa fa |
|------------|---------|---------|
| **Comprensione testo** | BGE-M3 | Trasforma testo in numeri che catturano il significato |
| **Primo filtro** | FlashRank | Scarta velocemente i documenti meno rilevanti |
| **Secondo filtro** | Qwen3 Reranker | Analisi fine per tenere solo il meglio |
| **Generazione risposte** | Llama 3.1 8B | Scrive risposte naturali e accurate |

### L'Infrastruttura

| Componente | Tecnologia | Ruolo |
|------------|------------|-------|
| **Database vettoriale** | Qdrant | Cerca documenti per significato, non per parole esatte |
| **Server LLM** | Ollama | Esegue i modelli AI localmente (niente cloud!) |
| **Interfaccia** | Chainlit | UI moderna con feedback integrato |
| **Autenticazione** | bcrypt + JWT | Login sicuro con ruoli RBAC |
| **Orchestrazione** | Python | Collega tutto insieme |

### Requisiti Hardware

- **GPU**: NVIDIA RTX 3060 6GB (o superiore)
- **RAM**: 16GB consigliati
- **Storage**: ~10GB per modelli e dati

---

## ğŸ—ï¸ Architettura Tecnica

### Schema del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              OVV ISO Chat v3.9                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         INGESTION PIPELINE                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   PDF    â”‚â”€â”€â–ºâ”‚ Extractorâ”‚â”€â”€â–ºâ”‚ Chunker  â”‚â”€â”€â–ºâ”‚ BGE-M3 Embedder  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Documentsâ”‚   â”‚ (PyMuPDF)â”‚   â”‚(Parent+  â”‚   â”‚ (Dense + Sparse) â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ Child)   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚            â”‚   â”‚
â”‚  â”‚                                                        â–¼            â”‚   â”‚
â”‚  â”‚                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚                                              â”‚     Qdrant       â”‚   â”‚   â”‚
â”‚  â”‚                                              â”‚  Vector Database â”‚   â”‚   â”‚
â”‚  â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                          RAG PIPELINE                                â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  Query   â”‚â”€â”€â–ºâ”‚ Glossary â”‚â”€â”€â–ºâ”‚ Hybrid   â”‚â”€â”€â–ºâ”‚    Reranking     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Input   â”‚   â”‚ Expansionâ”‚   â”‚ Retrievalâ”‚   â”‚ L1: FlashRank    â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ (40 docs)â”‚   â”‚ L2: Qwen3 GGUF   â”‚  â”‚   â”‚
â”‚  â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                        â”‚            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚                                                              â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Memory     â”‚ + â”‚  Top 5 Docs  â”‚ â”€â”€â–ºâ”‚  Llama 3.1 8B    â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Context    â”‚   â”‚  (Reranked)  â”‚   â”‚   (Generation)   â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                  â”‚           â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                     â–¼              â”‚   â”‚
â”‚  â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚                                            â”‚     Response     â”‚    â”‚   â”‚
â”‚  â”‚                                            â”‚   + Sources      â”‚    â”‚   â”‚
â”‚  â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         MEMORY SYSTEM                                â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚  Preferences â”‚   â”‚    Facts     â”‚   â”‚  Bayesian Feedback Boost â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  (User prefs)â”‚   â”‚  (Learned)   â”‚   â”‚  (0.8x - 1.2x scoring)   â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“„ Pipeline di Ingestion

### 1. Estrazione PDF (`extractor.py`)

```python
# Il documento viene aperto con PyMuPDF
PDF â†’ ExtractedDocument {
    metadata: {
        doc_type: "PS" | "IL" | "MR" | "TOOLS",
        chapter: "06",
        doc_number: "01",
        revision: "3",
        title: "Gestione Rifiuti",
        priority: 1.0  # PS=1.0, IL=0.9, MR=0.85, TOOLS=0.85
    },
    pages: [ExtractedPage...],
    full_text: "..."
}
```

**Pattern di estrazione filename:**
- `PS-06_01` â†’ Procedura di Sistema, Capitolo 06, Documento 01
- `IL-07_02` â†’ Istruzione di Lavoro, Capitolo 07, Documento 02
- `MR-10_03` â†’ Modulo di Registrazione, Capitolo 10, Documento 03

### 2. Chunking Gerarchico (`chunker.py`)

Il testo viene diviso in due livelli:

```
Documento Originale (es. 5000 caratteri)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PARENT CHUNKS                  â”‚
â”‚  (1200 caratteri, overlap 200)              â”‚
â”‚                                             â”‚
â”‚  [Parent 1] [Parent 2] [Parent 3] [Parent 4]â”‚
â”‚      â”‚          â”‚          â”‚          â”‚     â”‚
â”‚      â–¼          â–¼          â–¼          â–¼     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚Child â”‚  â”‚Child â”‚  â”‚Child â”‚  â”‚Child â”‚    â”‚
â”‚  â”‚ 1.1  â”‚  â”‚ 2.1  â”‚  â”‚ 3.1  â”‚  â”‚ 4.1  â”‚    â”‚
â”‚  â”‚Child â”‚  â”‚Child â”‚  â”‚Child â”‚  â”‚Child â”‚    â”‚
â”‚  â”‚ 1.2  â”‚  â”‚ 2.2  â”‚  â”‚ 3.2  â”‚  â”‚ 4.2  â”‚    â”‚
â”‚  â”‚Child â”‚  â”‚Child â”‚  â”‚Child â”‚  â”‚Child â”‚    â”‚
â”‚  â”‚ 1.3  â”‚  â”‚ 2.3  â”‚  â”‚ 3.3  â”‚  â”‚ 4.3  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  (400 caratteri ciascuno, overlap 100)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Strategia per tipo documento:**
- **Dense** (PS, IL): Parent + Child chunks â†’ ricerca dettagliata
- **Synthetic** (MR, TOOLS): Chunk generati da metadata semantici (v3.9)

### 2.5 Synthetic Chunking per MR/TOOLS (R30) - v3.9

I documenti **MR** (Moduli Registrazione) e **TOOLS** sono template tabellari vuoti, inutili se estratti direttamente da PDF. Il sistema genera **chunk sintetici** dai metadata:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROBLEMA: PDF MR/TOOLS = tabelle vuote                                   â”‚
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚ MR-10_01.pdf    â”‚ â†’ Estrazione â†’ "| Campo | Valore |" (inutile!)       â”‚
â”‚  â”‚ [Major Kaizen]  â”‚                                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚                                                                            â”‚
â”‚  SOLUZIONE: Chunk Sintetici da Metadata                                    â”‚
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ semantic_       â”‚     â”‚ ğŸ“„ MODULO: MR-10_01 - Major Kaizen           â”‚ â”‚
â”‚  â”‚ metadata.json   â”‚  â†’  â”‚ ğŸ“‚ Categoria: kaizen_project                  â”‚ â”‚
â”‚  â”‚ document_       â”‚     â”‚ ğŸ¯ USA QUANDO: progetto miglioramento         â”‚ â”‚
â”‚  â”‚ metadata.json   â”‚     â”‚ âš ï¸  NON USARE PER: quick kaizen, kaizen flash â”‚ â”‚
â”‚  â”‚ tools_mapping.  â”‚     â”‚ ğŸ”— PROCEDURA: PS-10_01                        â”‚ â”‚
â”‚  â”‚ json            â”‚     â”‚ ğŸ› ï¸  DA USARE CON: 4M Ishikawa, 5 PerchÃ©,     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     5W1H, Poka Yoke, QM Matrix                â”‚ â”‚
â”‚                          â”‚ ğŸ“‹ CAMPI: Team, Cronoprogramma, Budget...     â”‚ â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**File Metadata (config/):**

| File | Contenuto | Documenti |
|------|-----------|-----------|
| `semantic_metadata.json` | 90 voci con `applies_when`, `not_for`, `incident_category`, `related_keywords` | Tutti MR + TOOLS |
| `document_metadata.json` | Titolo, scopo, correlazioni estratte da PDF | MR + TOOLS |
| `tools_mapping.json` | Keywords, concepts, campi per R15/R16 | 93 tool mappati |

**Vantaggi:**
- ğŸ“ˆ **Retrieval migliorato**: I chunk sintetici contengono semantica ricca (es. "usa quando hai un infortunio")
- ğŸ”— **Correlazioni automatiche**: Il sistema suggerisce strumenti correlati (es. "Da usare con: 5 PerchÃ©, Ishikawa")
- ğŸ¯ **Intent matching**: Query "Ho avuto un infortunio" â†’ trova `MR-06_01` (Safety EWO) e non `MR-06_02` (Near Miss)
- ğŸ“Š **PrioritÃ  equilibrata**: MR ora ha prioritÃ  0.85 (era 0.5 - penalizzato)

### 2.7 Arricchimento Chunks - Prepending Context (R21)

Prima dell'embedding, ogni chunk (inclusi quelli sintetici) viene **arricchito** con contesto:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CHUNK ORIGINALE                                             â”‚
â”‚ "La gestione dei rifiuti pericolosi richiede..."           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CHUNK ARRICCHITO                                            â”‚
â”‚                                                             â”‚
â”‚ [DOC: PS-06_01 | Sezione: 4.2 | Titolo: Gestione Rifiuti]  â”‚
â”‚ [Glossario: CER = Catalogo Europeo Rifiuti]                â”‚
â”‚                                                             â”‚
â”‚ La gestione dei rifiuti pericolosi richiede...             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cosa viene aggiunto:**
- **Header contestuale**: doc_id, sezione, titolo, revisione
- **Glossario**: definizioni acronimi presenti nel chunk
- **Scopo documento**: solo per PS/IL (primi 200 caratteri)

**Benefici:**
- L'embedding cattura anche il contesto del documento
- Query "rifiuti PS-06" trova chunks del documento corretto
- Acronimi nel chunk sono ricercabili semanticamente

### 3. Embedding con BGE-M3 (`indexer.py`)

Ogni chunk viene trasformato in due tipi di vettori:

```python
Chunk Text: "La gestione dei rifiuti pericolosi richiede..."
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚         BGE-M3 Model          â”‚
              â”‚      (BAAI/bge-m3)            â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                                       â–¼
   Dense Vector                            Sparse Vector
   [0.012, -0.034, ...]                   {"rifiuti": 0.8, 
   (1024 dimensioni)                       "pericolosi": 0.7,
                                           "gestione": 0.5}
```

- **Dense Vector**: Cattura il significato semantico globale
- **Sparse Vector**: Cattura le parole chiave importanti (BM25-style)

### 4. Indicizzazione in Qdrant

```python
# Struttura del punto in Qdrant
{
    "id": "uuid-...",
    "vector": {
        "dense": [0.012, -0.034, ...],  # 1024 dim
        "sparse": {"indices": [...], "values": [...]}
    },
    "payload": {
        "text": "La gestione dei rifiuti...",
        "doc_id": "PS-06_01",
        "doc_type": "PS",
        "chapter": "06",
        "chunk_type": "parent",  # o "child"
        "priority": 1.0,
        "metadata": {...}
    }
}
```

---

## ğŸ” Pipeline di Retrieval

### Flow Completo della Query (v3.8)

```
Query: "Come gestire le NC nel processo?"
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  0. DISAMBIGUATION    â”‚  (R06)
        â”‚  NC ambiguo?          â”‚
        â”‚  Contesto: "processo" â”‚
        â”‚  â†’ Non ConformitÃ  âœ“   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1. GLOSSARY EXPANSION â”‚  (R20)
        â”‚  + Context Injection   â”‚
        â”‚  SGI â†’ Sistema di      â”‚
        â”‚  Gestione Integrato    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1.5 LLM QUERY EXPAND â”‚  (v3.8)
        â”‚  Genera sub-query     â”‚
        â”‚  per topic complessi  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  2. HyDE GENERATION   â”‚  (R23)
        â”‚  LLM genera documento  â”‚
        â”‚  ipotetico (150 parole)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3a. DOCS      â”‚       â”‚ 3b. GLOSSARY  â”‚  (R22)
â”‚ RETRIEVAL     â”‚       â”‚ RETRIEVAL     â”‚
â”‚ iso_sgi_docs  â”‚       â”‚ glossary_termsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3c. RRF MERGE        â”‚  (R22)
        â”‚  Reciprocal Rank      â”‚
        â”‚  Fusion + Boost       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  4. RERANK L1         â”‚
        â”‚  FlashRank (CPU)      â”‚
        â”‚  40 â†’ 15 documenti    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5. RERANK L2         â”‚
        â”‚  Qwen3 GGUF (CPU)     â”‚
        â”‚  15 â†’ 5 documenti     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6. MEMORY INJECTION  â”‚
        â”‚  + preferenze utente  â”‚
        â”‚  + fatti appresi      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6. LLM GENERATION    â”‚
        â”‚  Llama 3.1 8B (GPU)   â”‚
        â”‚  Risposta + Fonti     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dettaglio Reranking a 2 Livelli

```python
# Livello 1: FlashRank (veloce, CPU)
# Modello: ms-marco-MiniLM-L-12-v2
# Input: 40 documenti dal retrieval
# Output: Top 15 per relevance score

# Livello 2: Qwen3 Reranker (preciso, CPU)  
# Modello: Qwen3-Reranker-0.6B-GGUF
# Input: 15 documenti da L1
# Output: Top 5 per final score
```

PerchÃ© due livelli?
- **L1** Ã¨ velocissimo (~10ms) ma meno preciso
- **L2** Ã¨ piÃ¹ lento (~200ms) ma molto piÃ¹ accurato
- Combinandoli: velocitÃ  + qualitÃ 

---

## ğŸ“š Sistema Glossario

Il glossario Ã¨ il primo step della pipeline di query: **espande gli acronimi** prima della ricerca per migliorare il retrieval.

### Glossary Context Injection (R20)

Le definizioni degli acronimi vengono ora **iniettate esplicitamente** nel prompt dell'LLM:

```
ğŸ“š DEFINIZIONI ACRONIMI:
â€¢ WCM = World Class Manufacturing (metodologia di miglioramento continuo)
â€¢ PDCA = Plan-Do-Check-Act (ciclo di Deming)
â€¢ NC = Non ConformitÃ 
```

**PerchÃ© Ã¨ importante?**
- Prima: le definizioni erano nascoste tra parentesi nella query espansa
- Ora: l'LLM vede chiaramente le definizioni con **prioritÃ  visiva**
- Risultato: risposte piÃ¹ accurate che usano correttamente gli acronimi

### Dual Embedding - Glossario come Collezione (R22)

Il glossario Ã¨ ora indicizzato come **collezione Qdrant separata** (`glossary_terms`):

```
Query: "WCM"
    â”‚
    â”œâ”€â–º iso_sgi_docs (documenti)  â”€â”€â”
    â”‚                               â”‚
    â””â”€â–º glossary_terms (definizioni)â”œâ”€â”€â–º RRF Merge â”€â”€â–º Risultati
                                    â”‚
```

**Vantaggi:**
- Ricerca semantica sulle definizioni (non solo matching esatto)
- Query "cosa significa WCM?" trova la definizione via embedding
- Boost automatico per query definitorie (+50%)
- Reciprocal Rank Fusion (RRF) per merge risultati

### LLM Query Expansion Generale (v3.8)

Per query complesse o multi-aspetto, il sistema genera automaticamente **sub-query** per trovare TUTTE le informazioni rilevanti:

```
Query: "Come gestire i rifiuti?"
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM genera sub-query automaticamente:                       â”‚
â”‚                                                             â”‚
â”‚ Prompt: "Genera 2 sotto-query specifiche per questa        â”‚
â”‚          domanda. Rispondi SOLO con le query."             â”‚
â”‚                                                             â”‚
â”‚ Output:                                                     â”‚
â”‚ - gestione rifiuti non pericolosi raccolta differenziata   â”‚
â”‚ - gestione rifiuti pericolosi CER smaltimento              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
       3 query parallele
       (originale + 2 sub)
              â”‚
              â–¼
         Qdrant Search
```

**Caratteristiche:**
- **Generale**: Nessuna regola hardcoded, funziona per QUALSIASI argomento
- **Automatico**: Attivato per query con termini generici (gestire, procedure, normativa)
- **Fallback**: Se LLM timeout, usa query originale senza bloccare
- **Veloce**: Prompt breve (80 token max), timeout 30s, cache implicita

**Vantaggi:**
- Risposte piÃ¹ complete su argomenti con sottocategorie
- Non richiede configurazione per ogni nuovo topic
- L'LLM capisce semanticamente cosa espandere

### HyDE - Hypothetical Document Embeddings (R23)

Prima del retrieval, il sistema genera un **documento ipotetico** che risponde alla query:

```
Query: "come gestire i rifiuti pericolosi"
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM genera documento ipotetico (150 parole):                â”‚
â”‚ "La gestione dei rifiuti pericolosi secondo ISO 14001       â”‚
â”‚  prevede: identificazione CER, registro carico/scarico..."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         Embedding combinato:
         Query (25%) + Expanded (35%) + HyDE (40%)
                    â”‚
                    â–¼
              Qdrant Search
```

**Vantaggi:**
- Il documento ipotetico cattura pattern linguistici dei documenti reali
- Migliora precision retrieval del 15-20% per query complesse
- Template specifici per tipo documento (PS/IL/MR/TOOL)
- Skip automatico per query definitorie (giÃ  coperte da R20/R22)
- Cache documenti ipotetici (TTL 1 ora)

### FunzionalitÃ  del Glossario

| Funzione | Descrizione | Esempio |
|----------|-------------|---------|
| `resolve_acronym()` | Risolve singolo acronimo | `"PS"` â†’ `"Procedura di Sistema"` |
| `resolve_with_context()` | Disambigua con contesto (R06) | `"NC" + "audit"` â†’ `"Non ConformitÃ "` |
| `expand_query()` | Espande tutti gli acronimi | `"PS e IL"` â†’ `"PS (Procedura...) e IL (Istruzione...)"` |
| `fuzzy_match()` | Match approssimato | `"procedura"` â†’ suggerisce `"PS"` |
| `rewrite_query()` | Riscrittura completa + contesto | Aggiunge metadata documento |

### Aggiornamento Dinamico

Il glossario puÃ² essere arricchito dalla memoria:

```
/memoria fact Quick Kaizen si abbrevia QK
```

Questo aggiunge `QK â†’ Quick Kaizen` al glossario runtime.

---

## ğŸ§  Sistema di Memoria

### Tipi di Memoria Supportati

```python
class MemoryType(Enum):
    PREFERENCE = "preference"   # "Preferisco spiegazioni brevi"
    FACT = "fact"               # "Il Quick Kaizen si usa per miglioramenti rapidi"
    CORRECTION = "correction"   # "Non Ã¨ FIFO ma LIFO per i rifiuti"
    PROCEDURE = "procedure"     # "Per la NC usa sempre il modulo MR-08"
    CONTEXT = "context"         # Contesto conversazione
```

### Bayesian Feedback Boost

Ogni memoria ha un `boost_factor` che varia tra 0.8 e 1.2 basato sui feedback:

```
Memoria: "Preferisco Quick Kaizen"
         â”‚
         â”œâ”€ ğŸ‘ Positivo â†’ boost += 0.05 (max 1.2)
         â”‚
         â””â”€ ğŸ‘ Negativo â†’ boost -= 0.05 (min 0.8)

Score finale = base_confidence Ã— boost_factor
```

### Namespace Memorie

Ogni utente ha il proprio namespace per le memorie:
- **Personali**: `user_{id}` - visibili solo all'utente
- **Globali**: `global` - visibili a tutti (solo Admin puÃ² scrivere)

---

## ğŸ” Sistema di Autenticazione

### Ruoli e Permessi

**Permessi di LETTURA:**

| Cosa puÃ² leggere | `user` | `engineer` | `admin` |
|------------------|--------|------------|---------|
| Memorie globali | âœ… | âœ… | âœ… |
| Proprie memorie | âœ… | âœ… | âœ… |
| Memorie altri utenti | âŒ | âœ… | âœ… |

**Permessi di SCRITTURA:**

| Cosa puÃ² scrivere | `user` | `engineer` | `admin` |
|-------------------|--------|------------|---------|
| Proprie memorie | âœ… | âœ… | âœ… |
| Memorie globali | âŒ | âŒ | âœ… |
| Gestire utenti | âŒ | âŒ | âœ… |

### Gestione Utenti (Admin)

```bash
# Crea nuovo utente
python -c "
from src.auth.store import UserStore, Role
store = UserStore()
store.create_user('mario', 'password123', Role.USER, 'Mario Rossi')
"
```

### Servizi di Sistema

| Servizio | URL | Porta |
|----------|-----|-------|
| **Chainlit UI** | `http://localhost:7866` | 7866 |
| **Admin Panel** | `http://localhost:8501` | 8501 |
| **Qdrant DB** | `http://localhost:6333` | 6333 |
| **Ollama LLM** | `http://localhost:11434` | 11434 |

---

## ğŸ›ï¸ Admin Panel Streamlit

Il pannello amministrativo Ã¨ un'interfaccia web separata per la gestione centralizzata del sistema.

### Avvio Admin Panel

```powershell
cd D:\.ISO_OVV\ovv-iso-chat
poetry install --with ui
streamlit run admin_panel.py --server.port 8501
```

**URL:** `http://localhost:8501`

### FunzionalitÃ 

| Vista | Descrizione | Admin | Engineer |
|-------|-------------|-------|----------|
| **ğŸ“Š Dashboard** | KPI cards + grafici statistiche | âœ… Full | âœ… Read-only |
| **ğŸ“ˆ Analytics** | Metriche utilizzo, qualitÃ  RAG, report | âœ… Full | âœ… Read |
| **ğŸ¤ Consenso** | Apprendimento implicito, promozione memorie | âœ… Full | âœ… Read |
| **ğŸ“‹ Proposte** | Gestione proposte pending_global | âœ… Approve/Reject | âš ï¸ Solo Reject |
| **ğŸ“š Glossario** | CRUD acronimi con paginazione | âœ… CRUD | âœ… Read |
| **ğŸ§  Memorie** | Browser memorie per namespace | âœ… Full + Promote | âœ… Read |
| **ğŸ‘¥ Utenti** | Gestione account utenti | âœ… CRUD | âŒ Negato |

### Workflow Approvazione Proposte

1. **Utente** propone memoria con `/propose` nella chat
2. **Proposta** finisce in `pending_global`
3. **Admin/Engineer** vede proposte nel pannello
4. **Admin** puÃ² approvare â†’ memoria va in `global` + eventuale aggiunta glossario
5. **Admin/Engineer** puÃ² rifiutare â†’ proposta eliminata

### Estrazione Automatica Acronimi

Quando una proposta contiene una definizione di acronimo (es. "WCM = World Class Manufacturing"), il sistema:
1. Rileva il pattern
2. Estrae acronimo e definizione
3. Aggiunge automaticamente al `glossary.json` durante l'approvazione

---

## âš¡ Ottimizzazione VRAM (RTX 3060 6GB)

### Budget VRAM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    6144 MB TOTALE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  BGE-M3 Embedding     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â”‚  ~2200 MB  â”‚
â”‚  Llama 3.1 8B LLM     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚  ~3500 MB  â”‚
â”‚  Buffer sistema       â”‚â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚   ~400 MB  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TOTALE               â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚  ~6100 MB  â”‚
â”‚  (sotto soglia critica 5500 MB grazie a lazy load) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Strategie di Ottimizzazione

1. **Lazy Loading**: LLM caricato solo quando serve
2. **CPU Rerankers**: FlashRank e Qwen3 GGUF su CPU (0 VRAM)
3. **FP16 Embeddings**: BGE-M3 in half precision
4. **Batch ridotto**: 16 (fallback 8) per embedding
5. **GPU Layers**: 35 su 40 per LLM (bilancio velocitÃ /VRAM)

---

## ğŸ”§ Configurazione Avanzata

Modifica `config/config.yaml` per personalizzare:

```yaml
# Chunking
ingestion:
  chunking:
    parent_size: 1200    # Aumenta per piÃ¹ contesto
    child_size: 400      # Riduci per piÃ¹ precisione

# Retrieval
retrieval:
  top_k: 20              # PiÃ¹ documenti iniziali
  final_k: 5             # PiÃ¹ documenti in risposta

# LLM
llm:
  generation:
    temperature: 0.3     # 0=deterministico, 1=creativo
    num_gpu_layers: 35   # Riduci se poca VRAM
```

---

## ğŸ“Š Metriche di Performance

| Metrica | Valore Target | Note |
|---------|--------------|------|
| Latenza query | < 30s | Prima query piÃ¹ lenta (caricamento modelli) |
| Recall@5 | > 0.85 | 85% documenti rilevanti nei top 5 |
| VRAM max | < 5.5GB | Con margine di sicurezza |
| Throughput | ~2 query/min | Con GPU condivisa |

---

## ğŸ“ Struttura del Progetto

```
ovv-iso-chat/
â”œâ”€â”€ app.py                    # Interfaccia Gradio (legacy)
â”œâ”€â”€ app_chainlit.py           # Interfaccia Chainlit (v3.3)
â”œâ”€â”€ admin_panel.py            # Admin Panel Streamlit (v3.2.2)
â”œâ”€â”€ admin/                    # Modulo Admin Panel
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth.py               # Autenticazione admin
â”‚   â””â”€â”€ views/
â”‚       â”œâ”€â”€ dashboard.py      # KPI + grafici
â”‚       â”œâ”€â”€ analytics.py      # Metriche e report (R07-R11)
â”‚       â”œâ”€â”€ consensus.py      # Consenso multi-utente (R08-R10)
â”‚       â”œâ”€â”€ proposals.py      # Gestione proposte
â”‚       â”œâ”€â”€ glossary.py       # CRUD glossario
â”‚       â”œâ”€â”€ memories.py       # Browser memorie
â”‚       â””â”€â”€ users.py          # Gestione utenti
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml           # Configurazione principale
â”‚   â”œâ”€â”€ glossary.json         # Acronimi e abbreviazioni
â”‚   â”œâ”€â”€ users.json            # Database utenti (v3.2)
â”‚   â”œâ”€â”€ tools_mapping.json    # Mapping tool 93 entries (R15/R16)
â”‚   â”œâ”€â”€ semantic_metadata.json # 90 MR/TOOLS con metadata semantici (R30)
â”‚   â”œâ”€â”€ document_metadata.json # Metadati estratti da PDF (R30)
â”‚   â”œâ”€â”€ ps_mr_context.json    # Contesto MR estratto da PS (R30)
â”‚   â””â”€â”€ acronym_proposals.json # Proposte acronimi (R05)
â”œâ”€â”€ .chainlit/
â”‚   â””â”€â”€ config.toml           # Configurazione Chainlit
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ auth/                 # Autenticazione RBAC (v3.2)
â”‚   â”‚   â”œâ”€â”€ models.py         # User, Role
â”‚   â”‚   â”œâ”€â”€ store.py          # UserStore
â”‚   â”‚   â””â”€â”€ middleware.py     # Auth callbacks
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ extractor.py      # Estrazione PDF
â”‚   â”‚   â”œâ”€â”€ chunker.py        # Chunking gerarchico PS/IL
â”‚   â”‚   â”œâ”€â”€ synthetic_chunker.py # Chunk sintetici MR/TOOLS (R30)
â”‚   â”‚   â”œâ”€â”€ enricher.py       # Prepending Context + Semantic (R21, R30)
â”‚   â”‚   â”œâ”€â”€ indexer.py        # BGE-M3 + Qdrant
â”‚   â”‚   â””â”€â”€ glossary_indexer.py # Dual Embedding (R22)
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py   # Pipeline RAG completa (R20-R23, R30)
â”‚   â”‚   â”œâ”€â”€ glossary.py       # Espansione acronimi
â”‚   â”‚   â”œâ”€â”€ disambiguator.py  # Disambiguazione contestuale (R06)
â”‚   â”‚   â”œâ”€â”€ hyde.py           # HyDE Generator (R23)
â”‚   â”‚   â”œâ”€â”€ tool_suggester.py # Suggerimento Tool (R15)
â”‚   â”‚   â”œâ”€â”€ teach_assistant.py # Assistenza Compilazione (R16)
â”‚   â”‚   â””â”€â”€ citation_extractor.py # Estrazione citazioni (R14)
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py   # Orchestrazione pipeline multi-agent
â”‚   â”‚   â”œâ”€â”€ agent_retriever.py # Retrieval + Intent Detection (R30)
â”‚   â”‚   â”œâ”€â”€ agent_context.py  # Contesto + MR Injection (R30)
â”‚   â”‚   â”œâ”€â”€ agent_generator.py # Generazione risposta con moduli
â”‚   â”‚   â”œâ”€â”€ agent_validator.py # Validazione citazioni (R26)
â”‚   â”‚   â”œâ”€â”€ mr_injector.py    # Inietta moduli correlati (R30)
â”‚   â”‚   â””â”€â”€ state.py          # Stato pipeline condiviso
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ store.py          # Storage + Bayesian boost
â”‚   â”‚   â”œâ”€â”€ updater.py        # Aggiornamento memoria
â”‚   â”‚   â””â”€â”€ llm_agent.py      # Agent LLM per estrazione
â”‚   â”œâ”€â”€ analytics/            # Modulo Analytics (v3.4)
â”‚   â”‚   â”œâ”€â”€ gap_detector.py   # Segnalazione lacune (R19)
â”‚   â”‚   â”œâ”€â”€ gap_store.py      # Persistenza segnalazioni
â”‚   â”‚   â””â”€â”€ acronym_extractor.py # Estrazione acronimi (R05)
â”‚   â”œâ”€â”€ learning/             # Modulo Apprendimento (v3.5)
â”‚   â”‚   â”œâ”€â”€ signals/          # Raccolta segnali impliciti
â”‚   â”‚   â”œâ”€â”€ analyzers/        # Analisi comportamento
â”‚   â”‚   â”œâ”€â”€ consensus/        # Voting e promozione
â”‚   â”‚   â”œâ”€â”€ learners/         # Orchestrazione
â”‚   â”‚   â”œâ”€â”€ hooks.py          # Integrazione Chainlit
â”‚   â”‚   â””â”€â”€ scheduler.py      # Job notturni
â”‚   â””â”€â”€ main.py               # CLI principale
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input_docs/           # PDF da indicizzare
â”‚   â”œâ”€â”€ persist/              # Dati persistenti
â”‚   â””â”€â”€ logs/                 # Log applicazione
â””â”€â”€ benchmarks/
    â””â”€â”€ benchmark_models.py   # Test performance
```

---

## ğŸ”¥ FunzionalitÃ  Avanzate

### Warmup all'Avvio

All'avvio dell'applicazione, tutti i modelli vengono pre-caricati in memoria:

```
ğŸ”¥ Warmup modelli in corso...
âœ… LLM warmup OK
âœ… Embedding model warmup OK
âœ… FlashRank warmup OK
âœ… Glossary warmup OK
ğŸ‰ Warmup completato in 11.5s
```

**Beneficio**: La prima query Ã¨ veloce (~30s) invece dei 10+ minuti senza warmup.

### Query Reformulation con History

Il sistema capisce il **contesto conversazionale** e riformula le query di follow-up:

| Query Utente | Query Riformulata |
|--------------|-------------------|
| "Cos'Ã¨ la RI?" | "Cos'Ã¨ la RI (Richiesta di Investimento)?" |
| "e la RO?" | "Cos'Ã¨ la RO (Richiesta d'Offerta) e differenze con RI?" |
| "parlamene" | "Parlami di piÃ¹ su: [ultima query]" |
| "quindi la differenza?" | "Qual Ã¨ la differenza tra RI e RO? Spiega entrambi." |

**Pattern riconosciuti:**
- `parlamene` / `continua` / `dimmi` â†’ espande ultima query
- `e la X?` â†’ confronta con termine precedente
- `quindi la differenza?` â†’ richiede confronto esplicito

---

## ğŸ¯ FunzionalitÃ  UI Avanzate (v3.6)

### Disambiguazione Contestuale Acronimi (R06 v2.0)

Quando un acronimo ha **piÃ¹ significati possibili**, il sistema lo disambigua in modo **intelligente e contestuale** usando un sistema a punteggio pesato:

```
Query: "NC durante l'audit qualitÃ "
              â”‚
              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  1. CONTEXT ANALYSIS (60%)                           â”‚
   â”‚     Keywords match: "audit", "qualitÃ "               â”‚
   â”‚     â†’ QualitÃ  score: 0.85                            â”‚
   â”‚     â†’ ContabilitÃ  score: 0.10                        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  2. USER PREFERENCE (25%)                            â”‚
   â”‚     Preferenza salvata: contabilitÃ                   â”‚
   â”‚     â†’ QualitÃ  score: 0.40                            â”‚
   â”‚     â†’ ContabilitÃ  score: 1.00                        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  3. DOMAIN FREQUENCY (15%)                           â”‚
   â”‚     NC nel dominio ISO = qualitÃ  85%                 â”‚
   â”‚     â†’ QualitÃ  score: 0.85                            â”‚
   â”‚     â†’ ContabilitÃ  score: 0.15                        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  CALCOLO FINALE                                      â”‚
   â”‚  QualitÃ :     0.85Ã—60% + 0.40Ã—25% + 0.85Ã—15% = 0.74 â”‚
   â”‚  ContabilitÃ : 0.10Ã—60% + 1.00Ã—25% + 0.15Ã—15% = 0.33 â”‚
   â”‚                                                      â”‚
   â”‚  Gap = 0.41 > 0.35 (CERTAINTY_THRESHOLD)            â”‚
   â”‚  â†’ CERTO! âœ… Risposta automatica                     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
   NC = "Non ConformitÃ " (risolto automaticamente)
```

**Comportamento Intelligente:**

| Scenario | Gap | Comportamento |
|----------|-----|---------------|
| **Contesto chiaro** (audit, qualitÃ ) | â‰¥ 0.35 | NC = "Non ConformitÃ " automatico |
| **Contesto finanziario** (fattura) | â‰¥ 0.35 | NC = "Nota di Credito" automatico |
| **Contesto ambiguo** ("Mostrami le NC") | < 0.35 | Chiede con suggerimento |

**Se Chiede:**

```
ğŸ”¤ **NC** puÃ² significare:

**1. Non ConformitÃ ** ğŸ“ _probabile dal contesto: audit, qualitÃ _
**2. Nota di Credito** â­ _tua preferenza abituale_

â“ Quale intendi?
```

**Pesi e Costanti:**
| Parametro | Valore | Descrizione |
|-----------|--------|-------------|
| `WEIGHT_CONTEXT` | 60% | Il contesto della query domina |
| `WEIGHT_PREFERENCE` | 25% | Preferenze utente sono suggerimenti soft |
| `WEIGHT_FREQUENCY` | 15% | Frequenza nel dominio ISO |
| `CERTAINTY_THRESHOLD` | 0.35 | Gap minimo per decisione automatica |

**Override Tracking:**
Se il contesto vince spesso sulla preferenza utente, il sistema riduce gradualmente il peso della preferenza per quell'acronimo (evita di chiedere sempre la stessa cosa).

**Acronimi Ambigui Configurati:**

| Acronimo | Significato 1 | Significato 2 | Significato 3 |
|----------|---------------|---------------|---------------|
| **NC** | Non ConformitÃ  | Nota di Credito | - |
| **AC** | Azione Correttiva | Aria Condizionata | - |
| **PM** | Professional Maintenance | Project Manager | Preventive Maintenance |
| **QC** | Quality Control | Quick Change | - |
| **CDL** | Centro Di Lavoro | Ciclo Di Lavoro | - |

### Fonti Intelligenti (R14)

Le risposte mostrano **solo le fonti effettivamente citate** nella risposta:

```
ğŸ“š **Fonti citate:**
- PS-06_01 (92%) â† Click per preview
- IL-06_02 (87%)

âš ï¸ Attenzione: MR-06_03 citato ma non trovato nei documenti
```

**FunzionalitÃ :**
- Estrazione citazioni dal testo LLM con regex
- Filtraggio: solo documenti citati (non tutti i 5 recuperati)
- Preview cliccabile nel sidebar Chainlit
- Rilevamento "citazioni fantasma" (doc citati ma non esistenti)

### Correlazioni Strumenti Automatiche (R30)

Quando parli di un argomento che richiede l'uso di **moduli o strumenti**, il sistema li cita automaticamente nella risposta:

```
User: "Come compilo un Major Kaizen?"

ğŸ¤– Il modulo MR-10_01 (Major Kaizen) Ã¨ destinato ai progetti di 
miglioramento MAJOR con impatto significativo e team dedicato.

Per compilarlo correttamente, si devono seguire i campi relativi 
allo scopo e all'utilizzo del progetto.

ğŸ“Œ **Da utilizzare insieme a:**
- 5 PerchÃ© â†’ per trovare root cause
- 4M Ishikawa â†’ per analisi causa
- 5W1H â†’ per raccogliere dati iniziali
- QM Matrix â†’ per correlare difetti/cause
- Poka Yoke â†’ per soluzioni anti-errore

ğŸ“š Fonti: MR-10_01_Major Kaizen, PS-10_01_Miglioramento
```

**Come funziona:**
1. **Intent Detection**: Query analizzata per intent (kaizen, infortunio, near miss...)
2. **MR Injection**: Moduli correlati iniettati nel contesto dal `MRInjector`
3. **Semantic Chunks**: I chunk sintetici contengono le correlazioni giÃ  formattate
4. **LLM cita**: L'LLM include naturalmente le correlazioni nella risposta

**Vantaggi:**
- L'utente scopre strumenti che non conosceva
- Non deve cercare manualmente le correlazioni tra procedure
- Ogni modulo "spiega" con cosa va usato

### Suggerimento Tool Pratici (R15)

Dopo una risposta su problemi operativi, il sistema suggerisce **tool pratici**:

```
ğŸ“š Fonti citate: PS-08_08 (89%)
---
ğŸ› ï¸ **Tool consigliati per questo problema:**

ğŸ“Œ **Cartellino Anomalia** (MR-07_05)
   Registrazione anomalie/difetti

ğŸ“Œ **5W1H** (TOOLS-10_01)
   Analisi strutturata del problema

[ğŸ“ Come compilo Cartellino Anomalia?] [ğŸ“ Come compilo 5W1H?]
```

**FunzionalitÃ :**
- Intent detection: distingue query azionabili da informative
- Mapping JSON: **93 tool** con keywords/concepts (v3.9)
- Fallback semantico con embedding similarity
- Bottoni cliccabili che eseguono `/teach`

### Assistenza Compilazione Tool (R16)

Il comando `/teach` Ã¨ ora **interattivo**:

```
/teach FMEA
```

```
ğŸ“ **Come compilare FMEA** (MR-08_07)

[spiegazione dettagliata...]

ğŸ” **Hai bisogno di aiuto su un campo specifico?**

[ğŸ“‹ Mostra tutti i campi] [âš ï¸ Errori comuni] [ğŸ“„ Esempio compilato]
```

**Domande follow-up:**
```
User: "Non capisco il campo Severity"

ğŸ“‹ **Campo: Severity (S)**

GravitÃ  dell'effetto su scala 1-10

ğŸ’¡ **Suggerimenti:**
10=pericolo senza preavviso, 9=pericolo con preavviso, 1=nessun effetto
```

**FunzionalitÃ :**
- Contesto sessione: mantiene doc_id per 10 minuti
- Field detection: rileva domande su campi specifici
- **93 tool mappati** con campi e descrizioni (v3.9)
- Feedback tracker per Admin (`/teach_stats`)

### Segnalazione Lacune Intelligente (R19)

Quando il sistema non trova informazioni, propone di segnalare:

```
[Risposta RAG incerta...]

---
ğŸ“ **Possibile lacuna rilevata**

Non ho trovato una definizione chiara per **WCM**.

Ho trovato il termine in questi documenti ma senza definizione:
- `PS-06_01`
- `IL-07_02`

â“ **Vuoi segnalare questa lacuna all'Admin?**

[âœ… SÃ¬, segnala] [âŒ No, non serve]
```

**Segnali analizzati (5):**
1. Nessun documento recuperato
2. Score retrieval basso (<0.4)
3. LLM esprime incertezza (14 pattern)
4. Termine non nel glossario
5. Termine citato ma non definito

**Admin:** `/gaps` mostra statistiche e segnalazioni pending.

### Estrazione Automatica Acronimi (R05)

Il sistema estrae **automaticamente** definizioni di acronimi dai documenti:

**Pattern riconosciuti (5):**
```
1. WCM (World Class Manufacturing)     â†’ parentesi dopo
2. (World Class Manufacturing) WCM     â†’ parentesi prima
3. WCM significa World Class...        â†’ connettivo italiano
4. WCM = World Class Manufacturing     â†’ uguale/due punti
5. WCM, ovvero World Class...          â†’ connettivo italiano
```

**Workflow Admin:**
```
/acronyms                  â†’ Lista proposte pending
/acronyms approve WCM      â†’ Approva â†’ aggiunge al glossario
/acronyms reject XYZ motivo â†’ Rifiuta con motivo
/acronyms stats            â†’ Statistiche estrazione
```

**Validazione:**
- Confidence score 0-1 (soglia 0.6)
- Match iniziali (WCM = World Class Manufacturing âœ“)
- Blacklist ~50 termini comuni (IL, PS, ISO...)
- Skip se giÃ  nel glossario

### Apprendimento Implicito + Consenso Multi-Utente (R08-R10)

Il sistema **impara automaticamente** dalle tue interazioni senza richiedere feedback esplicito:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SEGNALI IMPLICITI TRACCIATI                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‹ Click su fonte citata     â†’ Documento utile             â”‚
â”‚  ğŸ“ Copia testo risposta      â†’ Contenuto rilevante         â”‚
â”‚  â±ï¸  Tempo lettura (dwell)     â†’ Risposta interessante       â”‚
â”‚  ğŸ“œ Scroll completo           â†’ Contenuto approfondito      â”‚
â”‚  ğŸ”„ Riformulazione query      â†’ Risposta non soddisfacente  â”‚
â”‚  â¡ï¸  Follow-up                 â†’ Vuole approfondire          â”‚
â”‚  âœ… /teach completato         â†’ Contenuto confermato        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pattern Comportamentali Rilevati:**

| Pattern | Cosa rileva | Azione automatica |
|---------|-------------|-------------------|
| **Preferenza formato** | Dwell time + scroll depth | "Preferisce risposte brevi/dettagliate" |
| **Interesse topic** | Documenti cliccati spesso | "Interessato a [topic]" |
| **Livello expertise** | Termini tecnici in query | "Utente esperto/base" |
| **Frustrazione** | Re-ask + quick dismiss | Alert per Admin |

**Consenso Multi-Utente:**

Quando piÃ¹ utenti confermano la stessa informazione, questa viene promossa automaticamente:

```
Utente 1: /teach "WCM = World Class Manufacturing"
Utente 2: copia "WCM significa World Class"
Utente 3: click su fonte che definisce WCM
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  CONSENSO RAGGIUNTO â”‚
         â”‚  3 utenti, score 0.8â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         Promozione automatica a
         memoria GLOBALE (o pending)
```

**Soglie consenso:**
- Minimo **3 utenti** diversi
- Score consenso **â‰¥ 0.7**
- SimilaritÃ  contenuto **â‰¥ 75%**

**Admin Panel - Tab Consenso (ğŸ¤):**

| Sottotab | FunzionalitÃ  |
|----------|--------------|
| **Dashboard** | Metriche segnali, candidati pronti, ratio positivi |
| **Candidati** | Lista con pulsanti Approva/Rifiuta per ogni candidato |
| **Promozioni** | Storico memorie promosse con stats |
| **Segnali** | Monitoraggio per tipo (click, copy, dwell, ecc.) |
| **Config** | Soglie, feature toggles, run manuale analisi |

**Job Notturni Automatici:**

| Ora | Job | Descrizione |
|-----|-----|-------------|
| 03:00 | Nightly Analysis | Analisi comportamento utenti |
| 04:00 | Consensus Check | Promozione memorie con consenso |
| 05:00 | Signal Cleanup | Pulizia dati vecchi (30gg retention) |

### Cronologia Conversazioni (R28)

Il sistema **logga automaticamente** tutte le conversazioni per analisi e miglioramento:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONVERSATION LOGGER                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ Sessione (per utente)                                   â”‚
â”‚  â”œâ”€â”€ user_id, role, started_at, ended_at                   â”‚
â”‚  â”œâ”€â”€ total_interactions, feedback_counts                   â”‚
â”‚  â””â”€â”€ interactions[]                                         â”‚
â”‚      â””â”€â”€ ğŸ’¬ Interazione (ogni Q&A)                         â”‚
â”‚          â”œâ”€â”€ query_original/reformulated/expanded          â”‚
â”‚          â”œâ”€â”€ response_text (risposta LLM completa)         â”‚
â”‚          â”œâ”€â”€ sources_cited, sources_missing                â”‚
â”‚          â”œâ”€â”€ latency_total_ms                              â”‚
â”‚          â”œâ”€â”€ feedback (positive/negative)                  â”‚
â”‚          â”œâ”€â”€ tools_suggested                               â”‚
â”‚          â””â”€â”€ gap_detected/reported                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dati registrati per ogni interazione:**

| Campo | Descrizione |
|-------|-------------|
| `query_original` | Domanda esatta dell'utente |
| `query_reformulated` | Query dopo reformulation con history |
| `query_expanded` | Query dopo espansione acronimi |
| `response_text` | Risposta LLM completa |
| `sources_cited` | doc_id effettivamente citati |
| `sources_missing` | Citazioni fantasma (allucinazioni) |
| `latency_total_ms` | Tempo totale risposta |
| `feedback` | positive/negative (se dato) |
| `gap_detected` | Se rilevata lacuna (R19) |
| `tools_suggested` | Tool consigliati (R15) |

**Comando `/history`:**

```
/history         â†’ Ultime 10 sessioni tue
/history 20      â†’ Ultime 20 sessioni
/history today   â†’ Solo oggi
/history all     â†’ Tutti gli utenti (Admin)
```

**Admin Panel - Tab "ğŸ’¬ Conversazioni":**

| FunzionalitÃ  | Descrizione |
|--------------|-------------|
| **ğŸ“Š KPI Cards** | Sessioni, messaggi, utenti unici, feedback ratio |
| **ğŸ“‹ Lista Sessioni** | Espandibili con dettaglio ogni Q&A |
| **ğŸ“¤ Export CSV** | Download cronologia filtrata |
| **ğŸ‘¥ Stats per Utente** | Tabella top utenti con metriche |
| **ğŸ—‘ï¸ Cleanup** | Rimuovi sessioni vecchie (Admin) |

**Persistenza:**
- Path: `data/persist/conversations/sess_*.json`
- Retention: 90 giorni (configurabile)
- Indice giornaliero per query rapide

---

# ğŸš€ Progetti Futuri

> FunzionalitÃ  pianificate per le prossime versioni

| ID | Progetto | Descrizione | PrioritÃ  |
|----|----------|-------------|----------|
| F04 | ImplicitLearner Integration | Integrare segnali impliciti (copy, click, dwell) nell'UI | Alta |
| F05 | GraphRAG Integration | Knowledge Graph per retrieval basato su relazioni tra entitÃ  | Media |
| F06 | UnifiedChunker | Chunker unificato PS/IL + MR/TOOLS per ingestion robusta | Alta âœ… |
| F07 | Mesop UI Alternative | Valutare migrazione a Google Mesop per eventi avanzati | Media |
| F08 | Valutazione Qwen3 8B | Benchmark Qwen3 vs Llama 3.1 per migliore supporto italiano | Bassa |
| F09 | Selettore Modello LLM | Scegliere Llama/Qwen dalla UI durante la conversazione | Alta |

### ğŸ¯ F09: Selettore Modello LLM Dinamico

Permettere all'utente di scegliere il modello LLM direttamente dalla UI:

```
âš™ï¸ IMPOSTAZIONI CHAT
â”œâ”€â”€ ğŸ¤– Modello LLM
â”‚   â”œâ”€â”€ ğŸ¦™ Llama 3.1 8B (Predefinito)
â”‚   â””â”€â”€ ğŸ‰ Qwen3 8B (Migliore italiano)
```

**FunzionalitÃ :**
- Pannello Settings con dropdown modello
- Comando `/model llama` o `/model qwen`
- Cambio modello in tempo reale durante la conversazione
- Indicatore modello attivo nella risposta

**Vantaggi:**
- Qwen3: Migliore supporto italiano (119 lingue), architettura MoE piÃ¹ efficiente
- Llama 3.1: Modello stabile e bilanciato, ottimo per uso generale

---

# ğŸ“œ Appendici

## ğŸ“œ Storico Versioni

### v3.9.1 (Dicembre 2025) - "PDF Consultabili & Citazioni Leggibili"
- ğŸ“– **PDF Consultabili in Sidebar** - I PDF si aprono direttamente nella sidebar (non download)
  - Usa `cl.Pdf(display="side")` per consultazione inline
  - Apertura automatica alla pagina 1
  - Nome completo file con revisione (es. `PS-06_01_Rev.04_Gestione della sicurezza.pdf`)
- ğŸ“ **Citazioni con Titoli Italiani** - Nel testo i doc_id vengono sostituiti con titoli leggibili
  - `PS-06_01` â†’ `"Gestione della sicurezza negli ambienti di lavoro"`
  - Virgolette italiane per citazioni nel testo
  - Post-processing automatico su ogni risposta
- ğŸ“š **Footer Fonti Migliorato**:
  - Nome COMPLETO: `doc_id_Rev.XX_Titolo italiano`
  - **Separazione PDF/Glossario**: prima documenti (ğŸ“„), poi termini glossario (ğŸ“)
  - Icone differenziate per tipo fonte
- ğŸ” **Retrieval per Query Definitorie** - Anche le domande sul glossario recuperano PDF correlati
  - Query "cosa significa EWO" ora mostra anche documenti correlati negli allegati
  - Top-5 documenti correlati aggiunti automaticamente
- ğŸ›¡ï¸ **Post-Processing Anti-Allucinazioni**:
  - `sanitize_invalid_citations()` - Rimuove citazioni non presenti nel contesto
  - `remove_llm_references_section()` - Rimuove sezioni "Riferimenti:" ridondanti
  - `replace_doc_ids_with_titles()` - Sostituisce codici con titoli leggibili
  - Grounding check attivo con threshold 0.6
- ğŸ“ **File modificati**:
  - `app_chainlit.py` - Post-processing, `cl.Pdf`, separazione fonti
  - `src/agents/orchestrator.py` - Retrieval in `direct_glossary_answer()`
  - `templates/chat.html` - Separazione fonti PDF/Glossario
  - `test_ui.py` - Stessa logica per UI test
  - `config/config.yaml` - `grounding_check.enabled: true`

### v3.9.0 (Dicembre 2025) - "Semantic Chunking & Tool Correlations"
- ğŸ§© **Synthetic Chunking per MR/TOOLS (R30)** - Chunk generati da metadata invece che da PDF vuoti
  - **SyntheticChunker**: Genera chunk semantici per 68 MR + 22 TOOLS
  - Chunk ricchi: titolo, scopo, `applies_when`, `not_for`, correlazioni
  - Es: "ğŸ“„ MR-10_01 - Major Kaizen | USA QUANDO: progetto miglioramento | DA USARE CON: 4M Ishikawa, 5 PerchÃ©..."
- ğŸ“Š **Semantic Metadata System** - 90 documenti analizzati manualmente
  - `semantic_metadata.json`: 90 voci con `incident_category`, `applies_when`, `not_for`
  - `document_metadata.json`: Metadati estratti da PDF (titolo, scopo, correlazioni)
  - `ps_mr_context.json`: Contesto MR estratto dai documenti PS correlati
- ğŸ¯ **Intent Detection migliorato** - Rileva automaticamente:
  - `real_injury` â†’ MR-06_01 (Safety EWO)
  - `near_miss` â†’ MR-06_02 (Near Miss Report)
  - `kaizen` â†’ MR-10_01, MR-10_02, TOOLS correlati
- ğŸ”— **Correlazioni Strumenti Automatiche** - La risposta include:
  > "...deve essere utilizzato insieme ad altri strumenti come il **5 PerchÃ©, Kaizen, Poka Yoke e OPL**"
- ğŸ’‰ **MR Injector** - Inietta moduli correlati direttamente nel contesto LLM
  - Basato su `ps_mr_context.json` per correlazioni PSâ†’MR
  - Attivato automaticamente quando PS recuperati
- ğŸ“ˆ **PrioritÃ  MR/TOOLS aumentata** - Da 0.5/0.8 a 0.85 (contenuto ora ricco)
- ğŸ”„ **Re-ingestion completa** - 2811 chunks (2713 PS/IL + 98 sintetici MR/TOOLS)
- ğŸ“ **File creati/modificati**:
  - `src/ingestion/synthetic_chunker.py` (NUOVO - ~250 righe)
  - `src/agents/mr_injector.py` (NUOVO)
  - `src/agents/agent_retriever.py` (Intent detection)
  - `src/ingestion/enricher.py` (Semantic context)
  - `scripts/reindex_with_enrichment.py` (Synthetic integration)
  - `config/semantic_metadata.json` (NUOVO - 90 entries)
  - `config/document_metadata.json` (NUOVO)
  - `config/ps_mr_context.json` (NUOVO)
  - `config/tools_mapping.json` (esteso a 93 entries)
  - `tests/test_synthetic_chunker.py` (NUOVO)
  - `tests/test_semantic_retrieval.py` (NUOVO)

### v3.8.0 (Dicembre 2025) - "General Query Expansion + Conversation Logger"
- ğŸ§  **LLM Query Expansion Generale** - L'LLM genera automaticamente sub-query per QUALSIASI domanda complessa
  - Nessuna regola hardcoded - soluzione completamente generale
  - Chiamata diretta Ollama con timeout 30s e fallback automatico
  - Attivato per query con termini generici (gestire, procedure, normativa)
  - Migliora completezza risposte su argomenti multi-aspetto
- ğŸ“„ **Citazioni con Titolo Descrittivo (F01)** - Le fonti mostrano il titolo completo del documento
  - Es: "IL-06_01 - Gestione dei rifiuti" invece di solo "IL-06_01"
  - Titolo estratto dai metadati PDF durante l'ingestion
  - Miglior leggibilitÃ  e comprensione per l'utente
- ğŸ“œ **Conversation Logger (R28)** - Cronologia completa di tutte le chat
  - **Session tracking**: Ogni sessione utente con metadata (inizio, fine, durata)
  - **Interaction logging**: Query completa, risposta LLM, fonti, latenza, feedback
  - **Comando `/history`**: Visualizza le tue sessioni passate
  - **Admin Panel Tab "ğŸ’¬ Conversazioni"**: Vista con filtri, KPI, export CSV
  - **Persistenza JSON**: Un file per sessione in `data/persist/conversations/`
  - **Retention**: 90 giorni configurabile
  - **19 test unitari** per validazione
- ğŸ—„ï¸ **Re-importazione Completa** - 150 documenti, 2787 chunks arricchiti
  - 1752 acronimi risolti automaticamente (R21)
  - Media +140 caratteri di contesto per chunk
  - Collection Qdrant pulita senza duplicati
- ğŸ“ **File creati/modificati**:
  - `src/analytics/collectors/conversation_logger.py` (NUOVO - ~600 righe)
  - `admin/views/conversations.py` (NUOVO - ~300 righe)
  - `app_chainlit.py` (integrazione logging sessioni)
  - `admin_panel.py` (nuova tab Conversazioni)
  - `config/config.yaml` (sezione conversation_logging)
  - `tests/test_conversation_logger.py` (NUOVO - 19 test)
  - `src/agents/agent_analyzer.py` - `_llm_expand_query()` generale
  - `src/integration/rag_pipeline.py` - `RetrievedDoc.title`
  - `src/agents/orchestrator.py` - `_SourceWrapper` con titolo
  - `test_ui.py` e `templates/chat.html` - Display titolo fonti

### v3.7.0 (Dicembre 2025) - "Anti-Hallucination"
- ğŸ›¡ï¸ **ValidatorAgent (R26)** - Citazioni verificate automaticamente
  - **Citation Check**: Verifica che documenti citati siano nel contesto
  - **Self-Refine Loop**: Rigenera risposta con feedback se invalida (max 2 retry)
  - **Context Injection**: Header esplicito con doc_id disponibili nel prompt
  - **Zero VRAM overhead**: Validazione regex-based CPU-only
- ğŸ”„ **Flow Pipeline Aggiornato**:
  ```
  generator â†’ validator â†’ [VALID? END : generator(retry)]
  ```
- ğŸ“ **File modificati/creati**:
  - `src/agents/agent_validator.py` (NUOVO)
  - `src/agents/state.py` (campi validazione)
  - `src/agents/agent_context.py` (doc_id header injection)
  - `src/agents/agent_generator.py` (retry prompt template)
  - `src/agents/orchestrator.py` (validation loop)
  - `config/config.yaml` (sezione validator)
  - `tests/test_validator_agent.py` (NUOVO)

### v3.6.1 (Dicembre 2025) - "Conversational Assistant"
- ğŸ—£ï¸ **System Prompt Discorsivo** - Risposte piÃ¹ complete e proattive
  - Prompt ottimizzato per modelli 8B (conciso ma incisivo)
  - Istruzioni POSITIVE (cosa fare) vs restrizioni (cosa non fare)
  - 4 comportamenti chiave: contestualizza, dettaglia, suggerisci, interagisci
- ğŸ“ **File modificati**: `config/config.yaml`, `src/memory/llm_agent.py`

### v3.6.0 (Dicembre 2025) - "Smart Disambiguation"
- ğŸ¯ **Disambiguazione Contestuale (R06 v2.0)** - Acronimi ambigui risolti intelligentemente
  - Contesto query domina (60%), preferenze utente soft (25%), frequenza dominio (15%)
  - `CERTAINTY_THRESHOLD = 0.35` per decisione automatica
  - Chiede solo quando gap tra top 2 significati < soglia
  - Keywords contestuali per ogni significato (audit â†’ qualitÃ , fattura â†’ contabilitÃ )
  - Acronimi: NC, AC, PM, QC, CDL con significati multipli
  - Preferenze utente per file separato per utente
  - Override tracking: traccia quando il contesto batte la preferenza
- ğŸ“ **File**: `src/integration/disambiguator.py` (v2.0 fuso)
- âœ… **Test**: 39 test per disambiguazione contestuale

### v3.5.0 (Dicembre 2025) - "Learning & Consensus Complete"
- ğŸ§  **Apprendimento Implicito (R08)** - Sistema impara dalle interazioni senza feedback esplicito
- ğŸ¤ **Consenso Multi-Utente (R10)** - Promozione automatica memorie quando 3+ utenti confermano
- ğŸ“Š **Behavior Analyzer** - Rileva preferenze, interessi, expertise, frustrazioni
- ğŸ—³ï¸ **Voting Tracker** - Traccia voti impliciti per consenso
- ğŸš€ **Global Promoter** - Promuove memorie userâ†’global con validazione
- ğŸ›ï¸ **Admin Panel: Tab Consenso** - Dashboard, candidati, promozioni, segnali, config
- â° **Job Notturni** - Analisi@03:00, Consenso@04:00, Cleanup@05:00

### v3.4.0 (Dicembre 2025) - "UI Chat Stream Complete"
- ğŸ” **Fonti Intelligenti (R14)** - Mostra solo fonti citate + preview cliccabile
- ğŸ› ï¸ **Suggerimento Tool Pratici (R15)** - Bottoni per tool consigliati
- ğŸ“ **Assistenza Compilazione (R16)** - `/teach` interattivo con field detection
- ğŸ“ **Segnalazione Lacune (R19)** - Rileva e segnala gap nella knowledge base
- ğŸ”¤ **Estrazione Acronimi (R05)** - Estrae automaticamente definizioni dai documenti

### v3.3.0 (Dicembre 2025) - "Glossary Stream Complete"
- ğŸ”® **HyDE (R23)** - Genera documento ipotetico per migliorare retrieval
- ğŸ“š **Dual Embedding (R22)** - Glossario come collezione Qdrant separata
- ğŸ“ **Prepending Context (R21)** - Chunks arricchiti con metadata e glossario
- ğŸ’‰ **Glossary Context Injection (R20)** - Definizioni iniettate nel prompt LLM

### v3.2.2 (Dicembre 2025)
- ğŸ›ï¸ **Admin Panel Streamlit** - Pannello visuale su porta 8501
- ğŸ” **Fonti Intelligenti** - Mostra solo fonti effettivamente citate
- ğŸ§¹ **Deduplicazione Chunks** - Rimozione duplicati in ingestion
- âœï¸ **Fix Citazioni Fantasma** - LLM non inventa piÃ¹ documenti

### v3.2.1 (Dicembre 2025)
- ğŸ“– **Glossario Acronimi Ambigui** - Supporto significati multipli (es. CDL)
- ğŸ¤– **Apprendimento Semi-Automatico** - Sistema rileva quando insegni qualcosa
- âœ… **Sistema Approvazione** - Comandi `/pending`, `/approve`, `/reject`
- ğŸ“‹ **Namespace pending_global** - Proposte in coda per Admin

### v3.2.0 (Dicembre 2025)
- ğŸ” **Autenticazione RBAC** - Ruoli Admin/Engineer/User
- ğŸ‘ **Feedback Bayesian** - Sistema impara dai tuoi feedback
- ğŸ“„ **Preview Documenti** - Anteprima cliccabile delle fonti
- ğŸ§  **Namespace Multi-utente** - Memorie personali + globali
- ğŸ’¬ **Interfaccia Chainlit** - UI moderna

---

## ğŸ¤ Contribuire

1. Fork del repository
2. Crea branch feature (`git checkout -b feature/nuova-funzione`)
3. Commit (`git commit -m 'Aggiunge nuova funzione'`)
4. Push (`git push origin feature/nuova-funzione`)
5. Apri Pull Request

---

## ğŸ“ Licenza

MIT License - vedi [LICENSE](LICENSE) per dettagli.

---

## ğŸ™ Ringraziamenti

- [BAAI](https://huggingface.co/BAAI) per BGE-M3
- [Meta AI](https://huggingface.co/meta-llama) per Llama 3.1
- [Qwen](https://huggingface.co/Qwen) per il reranker
- [Qdrant](https://qdrant.tech/) per il vector database
- [Chainlit](https://chainlit.io/) per l'interfaccia chat

---

*Sviluppato con â¤ï¸ per semplificare la gestione documentale ISO*
