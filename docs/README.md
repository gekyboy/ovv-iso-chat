# OVV ISO Chat v3.1

> Sistema RAG locale per documenti ISO-SGI con memoria persistente.

## ğŸš€ Quick Start

```powershell
# 1. Setup ambiente
.\scripts\setup.ps1

# 2. Attiva venv
.\venv\Scripts\Activate.ps1

# 3. Verifica installazione
pytest tests/ -v

# 4. Avvia chat (dopo ingestion)
python -m src.main
```

## ğŸ“‹ Requisiti

- **Python**: 3.12+
- **GPU**: NVIDIA RTX 3060 6GB (o superiore)
- **Docker**: Per Qdrant
- **Ollama**: Per LLM locale

## ğŸ—ï¸ Struttura

```
ovv-iso-chat/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/     # Estrazione e chunking PDF
â”‚   â”œâ”€â”€ memory/        # Memoria LangGraph
â”‚   â””â”€â”€ integration/   # Pipeline RAG
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml    # Configurazione v3.1
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input_docs/    # PDF sorgente
â”‚   â”œâ”€â”€ persist/       # Memoria persistente
â”‚   â””â”€â”€ logs/          # Log applicazione
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup.ps1      # Setup automatico
â”œâ”€â”€ tests/             # Test suite
â””â”€â”€ benchmarks/        # Benchmark performance
```

## ğŸ”§ Stack Tecnologico

| Componente | Modello | Device |
|------------|---------|--------|
| Embedding | BAAI/bge-m3 | CUDA |
| Reranker L1 | FlashRank | CPU |
| Reranker L2 | Qwen3 GGUF | CPU |
| LLM | qwen3:8b-q4 | CUDA |
| Vector DB | Qdrant | Docker |

## ğŸ“– Documentazione

- `SESSION_CONTEXT.md` - Stato corrente del progetto
- `FUSION_LOG.md` - Log decisioni e merge

## ğŸ§ª Test

```powershell
# Test completi
pytest tests/ -v

# Test specifico
pytest tests/test_ingestion.py -v

# Con coverage
pytest tests/ --cov=src
```

## ğŸ“Š Vincoli VRAM

- **Warning**: 5000 MB
- **Critical**: 5500 MB
- **Strategia**: Lazy load LLM, reranker CPU, batch ridotti

---

*v3.1.0 - Setup Minimo per MVP*

